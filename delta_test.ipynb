{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install delta-spark==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql.types import _parse_datatype_string\n",
    "from pyspark.sql.functions import input_file_name, monotonically_increasing_id, row_number, regexp_extract, col, concat, sha2, to_timestamp, lit, desc, lag, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import pyspark\n",
    "from delta import *\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_time = datetime.now()\n",
    "exec_time_str = exec_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "high_date = \"2999-12-31 23:59:59\"\n",
    "\n",
    "year, month, day, hour, minute = map(str, exec_time.strftime(\"%Y %m %d %H %M\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-17 19:02:44|2023-07-18 11:20:31|                 1|                 2|2023|   07| 17|  19|    02|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  4|      Zoey|    Tucker|file:///Users/sai...|1818ea471269caa72...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  5|    Nathan|   Mcclain|file:///Users/sai...|e2cc62e08ad845909...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  6|   Shyanne|       Liu|file:///Users/sai...|547811bdef1d46e0a...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  1|   Belinda|    Waters|file:///Users/sai...|5877452deb0c15143...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-02 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  7|   Rodrigo|    Sparks|file:///Users/sai...|5d664cbfd64c26514...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_schema_str = (\n",
    "        \"id int, first_name string,last_name string, source string, hash string, is_active string, start_tmst timestamp, \"\n",
    "        \"end_tmst timestamp, create_tmst timestamp, update_tmst timestamp, created_by_exec_id int, updated_by_exec_id int, \"\n",
    "        \"year string, month string, day string, hour string, minute string\"\n",
    "    )\n",
    "\n",
    "delta_schema = _parse_datatype_string(delta_schema_str)\n",
    "delta_path = f\"{os.getcwd()}/delta\"\n",
    "\n",
    "partition_columns = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "\n",
    "if not DeltaTable.isDeltaTable(spark, delta_path):\n",
    "    print(\"Not a delta table. Creating delta table...\")\n",
    "    empty_df = spark.createDataFrame([], delta_schema)\n",
    "\n",
    "    empty_df.write.format(\"delta\") \\\n",
    "                .mode(\"append\") \\\n",
    "                .partitionBy(*partition_columns) \\\n",
    "                .save(delta_path)\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "delta_df = delta_table.toDF()\n",
    "delta_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_staging_df_from_raw(raw_schema_str, path):\n",
    "    raw_schema = _parse_datatype_string(raw_schema_str)\n",
    "\n",
    "    raw_df = spark.read.csv(path, header=True, schema=raw_schema)\n",
    "\n",
    "    timestamp_pattern = r\"(\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}-\\d{2})\"\n",
    "\n",
    "    staging_df = raw_df.withColumn(\"extract_tmst\", to_timestamp(regexp_extract(input_file_name(), timestamp_pattern, 1), \"yyyy-MM-dd-HH-mm-ss\")) \\\n",
    "                       .withColumn(\"source\", input_file_name()) \\\n",
    "                       .withColumn(\"hash\", sha2(concat(*raw_df.columns), 256))\n",
    "\n",
    "    return staging_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- extract_tmst: timestamp (nullable = true)\n",
      " |-- source: string (nullable = false)\n",
      " |-- hash: string (nullable = true)\n",
      "\n",
      "+---+----------+----------+-------------------+--------------------+--------------------+\n",
      "| id|first_name| last_name|       extract_tmst|              source|                hash|\n",
      "+---+----------+----------+-------------------+--------------------+--------------------+\n",
      "|  1|   Belinda|  Sullivan|2023-07-01 00:58:00|file:///Users/sai...|1863cefdfa2cde755...|\n",
      "|  1|   Belinda|   Hendrix|2023-07-01 00:58:00|file:///Users/sai...|e974f0bffc47aec5a...|\n",
      "|  2|      Lexi|     Walls|2023-07-01 00:58:00|file:///Users/sai...|83b9e894466f70135...|\n",
      "|  3|   Sherlyn|Williamson|2023-07-01 00:58:00|file:///Users/sai...|bf96251ef7d0ab4d8...|\n",
      "|  1|   Belinda|   Hendrix|2023-07-02 00:58:00|file:///Users/sai...|e974f0bffc47aec5a...|\n",
      "|  1|   Belinda|    Waters|2023-07-02 00:58:00|file:///Users/sai...|5877452deb0c15143...|\n",
      "|  7|   Rodrigo|    Sparks|2023-07-02 00:58:00|file:///Users/sai...|5d664cbfd64c26514...|\n",
      "+---+----------+----------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_schema_str = \"id int,first_name string,last_name string\"\n",
    "path = \"./raw/first_load/\"\n",
    "\n",
    "staging_df = create_staging_df_from_raw(raw_schema_str, path)\n",
    "staging_df.printSchema()\n",
    "staging_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- extract_tmst: timestamp (nullable = true)\n",
      " |-- source: string (nullable = false)\n",
      " |-- hash: string (nullable = true)\n",
      " |-- eff_end_tmst: timestamp (nullable = true)\n",
      "\n",
      "+---+----------+----------+-------------------+--------------------+--------------------+-------------------+\n",
      "| id|first_name| last_name|       extract_tmst|              source|                hash|       eff_end_tmst|\n",
      "+---+----------+----------+-------------------+--------------------+--------------------+-------------------+\n",
      "|  1|   Belinda|    Waters|2023-07-02 00:58:00|file:///Users/sai...|5877452deb0c15143...|               null|\n",
      "|  1|   Belinda|   Hendrix|2023-07-02 00:58:00|file:///Users/sai...|e974f0bffc47aec5a...|2023-07-02 00:58:00|\n",
      "|  1|   Belinda|   Hendrix|2023-07-01 00:58:00|file:///Users/sai...|e974f0bffc47aec5a...|2023-07-02 00:58:00|\n",
      "|  1|   Belinda|  Sullivan|2023-07-01 00:58:00|file:///Users/sai...|1863cefdfa2cde755...|2023-07-01 00:58:00|\n",
      "|  2|      Lexi|     Walls|2023-07-01 00:58:00|file:///Users/sai...|83b9e894466f70135...|               null|\n",
      "|  3|   Sherlyn|Williamson|2023-07-01 00:58:00|file:///Users/sai...|bf96251ef7d0ab4d8...|               null|\n",
      "|  7|   Rodrigo|    Sparks|2023-07-02 00:58:00|file:///Users/sai...|5d664cbfd64c26514...|               null|\n",
      "+---+----------+----------+-------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"id\").orderBy(desc(\"extract_tmst\"), desc(monotonically_increasing_id()))\n",
    "staging_df = staging_df.withColumn(\"eff_end_tmst\", lag(\"extract_tmst\").over(window_spec))\n",
    "\n",
    "staging_df.printSchema()\n",
    "staging_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|    Waters|file:///Users/sai...|5877452deb0c15143...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-02 00:58:00|2023-07-02 00:58:00|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        N|2023-07-01 00:58:00|2023-07-01 00:58:00|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "|  7|   Rodrigo|    Sparks|file:///Users/sai...|5d664cbfd64c26514...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:28:50|2023-07-18 11:28:50|                 2|                 2|2023|   07| 18|  11|    28|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_df = staging_df.withColumn(\"is_active\", when(col(\"eff_end_tmst\").isNull(), lit(\"Y\")).otherwise(lit(\"N\"))) \\\n",
    "                .withColumn(\"start_tmst\", col(\"extract_tmst\")) \\\n",
    "                .withColumn(\"end_tmst\", when(col(\"eff_end_tmst\").isNull(), to_timestamp(lit(high_date), \"yyyy-MM-dd HH:mm:ss\")).otherwise(col(\"eff_end_tmst\"))) \\\n",
    "                .withColumn(\"create_tmst\", to_timestamp(lit(exec_time_str), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                .withColumn(\"update_tmst\", to_timestamp(lit(exec_time_str), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                .withColumn(\"created_by_exec_id\", lit(2)) \\\n",
    "                .withColumn(\"updated_by_exec_id\", lit(2)) \\\n",
    "                .withColumn(\"year\", lit(year)) \\\n",
    "                .withColumn(\"month\", lit(month)) \\\n",
    "                .withColumn(\"day\", lit(day)) \\\n",
    "                .withColumn(\"hour\", lit(hour)) \\\n",
    "                .withColumn(\"minute\", lit(minute)) \\\n",
    "                .drop(\"extract_tmst\") \\\n",
    "                .drop(\"eff_end_tmst\")\n",
    "\n",
    "staging_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_df = staging_df.alias(\"stage\")\n",
    "delta_df = delta_df.alias(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = [col(\"stage.id\") == col(\"target.id\"), col(\"stage.hash\") != col(\"target.hash\"), col(\"stage.is_active\") == \"Y\", col(\"target.is_active\") == \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+------+----+---------+----------+--------+-----------+-----------+------------------+------------------+----+-----+---+----+------+---+----------+---------+------+----+---------+----------+--------+-----------+-----------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name|last_name|source|hash|is_active|start_tmst|end_tmst|create_tmst|update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute| id|first_name|last_name|source|hash|is_active|start_tmst|end_tmst|create_tmst|update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+---------+------+----+---------+----------+--------+-----------+-----------+------------------+------------------+----+-----+---+----+------+---+----------+---------+------+----+---------+----------+--------+-----------+-----------+------------------+------------------+----+-----+---+----+------+\n",
      "+---+----------+---------+------+----+---------+----------+--------+-----------+-----------+------------------+------------------+----+-----+---+----+------+---+----------+---------+------+----+---------+----------+--------+-----------+-----------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = delta_df.join(staging_df, cond, how=\"inner\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'((((NOT (stage.hash = target.hash)) OR (target.hash IS NULL)) AND (stage.is_active = Y)) AND (target.is_active = Y))'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_condition = ((col(\"stage.hash\") != col(\"target.hash\")) | col(\"target.hash\").isNull()) & (col(\"stage.is_active\") == \"Y\") & (col(\"target.is_active\") == \"Y\")\n",
    "joined_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name|last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute| id|first_name|last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda| Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|  1|   Belinda|   Waters|file:///Users/sai...|5877452deb0c15143...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = delta_df.join(staging_df, col(\"stage.id\")==col(\"target.id\"), how=\"inner\").where(joined_condition)\n",
    "# joined_df.printSchema()\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name|last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda| Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-17 19:02:44|2023-07-18 11:20:31|                 1|                 2|2023|   07| 17|  19|    02|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target_cols = [f\"target.{col}\" for col in delta_df.columns]\n",
    "# staging_cols \n",
    "\n",
    "\n",
    "updated_df = (\n",
    "    joined_df\n",
    "    .select(\n",
    "        \"target.*\",\n",
    "        col(\"stage.start_tmst\").alias(\"stage_start_tmst\"),\n",
    "        col(\"stage.create_tmst\").alias(\"stage_create_tmst\"),\n",
    "        col(\"stage.created_by_exec_id\").alias(\"stage_created_by_exec_id\")\n",
    "    )\n",
    "    .withColumn(\"is_active\", lit(\"N\"))\n",
    "    .withColumn(\"end_tmst\", col(\"stage_start_tmst\"))\n",
    "    .withColumn(\"update_tmst\", col(\"stage_create_tmst\"))\n",
    "    .withColumn(\"updated_by_exec_id\", col(\"stage_created_by_exec_id\"))\n",
    "    .drop(\"stage_start_tmst\", \"stage_create_tmst\", \"stage_created_by_exec_id\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "updated_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|    Waters|file:///Users/sai...|5877452deb0c15143...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-02 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  7|   Rodrigo|    Sparks|file:///Users/sai...|5d664cbfd64c26514...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-17 19:02:44|2023-07-18 11:20:31|                 1|                 2|2023|   07| 17|  19|    02|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "union_df = staging_df.union(updated_df)\n",
    "union_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|    Waters|file:///Users/sai...|5877452deb0c15143...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-02 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  7|   Rodrigo|    Sparks|file:///Users/sai...|5d664cbfd64c26514...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-17 19:02:44|2023-07-18 11:20:31|                 1|                 2|2023|   07| 17|  19|    02|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "union_df = staging_df.unionByName(updated_df).select(*updated_df.columns)\n",
    "union_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  6|   Shyanne|       Liu|file:///Users/sai...|547811bdef1d46e0a...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  5|    Nathan|   Mcclain|file:///Users/sai...|e2cc62e08ad845909...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  4|      Zoey|    Tucker|file:///Users/sai...|1818ea471269caa72...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "delta_df = delta_table.toDF()\n",
    "delta_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-17 19:02:44|2023-07-18 11:20:31|                 1|                 2|2023|   07| 17|  19|    02|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  4|      Zoey|    Tucker|file:///Users/sai...|1818ea471269caa72...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  5|    Nathan|   Mcclain|file:///Users/sai...|e2cc62e08ad845909...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  6|   Shyanne|       Liu|file:///Users/sai...|547811bdef1d46e0a...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  1|   Belinda|    Waters|file:///Users/sai...|5877452deb0c15143...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-02 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  1|   Belinda|   Hendrix|file:///Users/sai...|e974f0bffc47aec5a...|        N|2023-07-01 00:58:00|2023-07-02 00:58:00|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "|  7|   Rodrigo|    Sparks|file:///Users/sai...|5d664cbfd64c26514...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-18 11:20:31|2023-07-18 11:20:31|                 2|                 2|2023|   07| 18|  11|    20|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "\n",
    "\n",
    "condition = \"target.id==updates.id AND target.hash==updates.hash\"\n",
    "\n",
    "delta_table.alias(\"target\").merge(\n",
    "        union_df.alias(\"updates\"),\n",
    "        condition\n",
    "    ).whenMatchedUpdateAll(\n",
    "        condition=\"target.is_active!=updates.is_active\"\n",
    "    ).whenNotMatchedInsertAll(\n",
    "    ).execute()\n",
    "\n",
    "delta_table_df = delta_table.toDF()\n",
    "delta_table_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the required columns from the updated df. Union them with the staging df\n",
    "\n",
    "merge union df into delta\n",
    "condition source and target id and hash match\n",
    "when match update condition source.is_active != target.is_active\n",
    "when does not match insert\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------------------+--------------------+--------------------+\n",
      "| id|first_name|last_name|       extract_tmst|              source|                hash|\n",
      "+---+----------+---------+-------------------+--------------------+--------------------+\n",
      "|  7|   Rodrigo|   Sparks|2023-07-02 00:58:00|file:///Users/sai...|5d664cbfd64c26514...|\n",
      "+---+----------+---------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_new_records = staging_df.alias(\"stage\").join(delta_df.alias(\"target\"), on=\"id\", how=\"leftanti\")\n",
    "_new_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- source: string (nullable = false)\n",
      " |-- hash: string (nullable = true)\n",
      " |-- is_active: string (nullable = false)\n",
      " |-- start_tmst: timestamp (nullable = true)\n",
      " |-- end_tmst: timestamp (nullable = true)\n",
      " |-- create_tmst: timestamp (nullable = true)\n",
      " |-- update_tmst: timestamp (nullable = true)\n",
      " |-- created_by_exec_id: integer (nullable = false)\n",
      " |-- updated_by_exec_id: integer (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- month: string (nullable = false)\n",
      " |-- day: string (nullable = false)\n",
      " |-- hour: string (nullable = false)\n",
      " |-- minute: string (nullable = false)\n",
      "\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name|last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  7|   Rodrigo|   Sparks|file:///Users/sai...|5d664cbfd64c26514...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_records = _new_records.withColumn(\"is_active\", lit(\"Y\")) \\\n",
    "                          .withColumn(\"start_tmst\", col(\"extract_tmst\")) \\\n",
    "                          .withColumn(\"end_tmst\", to_timestamp(lit(high_date), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                          .withColumn(\"create_tmst\", to_timestamp(lit(exec_time_str), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                          .withColumn(\"update_tmst\", to_timestamp(lit(exec_time_str), \"yyyy-MM-dd HH:mm:ss\")) \\\n",
    "                          .withColumn(\"created_by_exec_id\", lit(1)) \\\n",
    "                          .withColumn(\"updated_by_exec_id\", lit(1)) \\\n",
    "                          .withColumn(\"year\", lit(year)) \\\n",
    "                          .withColumn(\"month\", lit(month)) \\\n",
    "                          .withColumn(\"day\", lit(day)) \\\n",
    "                          .withColumn(\"hour\", lit(hour)) \\\n",
    "                          .withColumn(\"minute\", lit(minute)) \\\n",
    "                          .drop(\"extract_tmst\")\n",
    "\n",
    "new_records.printSchema()\n",
    "new_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'((NOT (stage.hash = target.hash)) OR (target.hash IS NULL))'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates_condition = (col(\"stage.hash\") != col(\"target.hash\")) | col(\"target.hash\").isNull()\n",
    "updates_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-------------------+--------------------+--------------------+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name|last_name|       extract_tmst|              source|                hash|first_name|last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+---------+-------------------+--------------------+--------------------+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|  Hendrix|2023-07-02 00:58:00|file:///Users/sai...|5620d42bea3b111f0...|   Belinda| Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "+---+----------+---------+-------------------+--------------------+--------------------+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_records = staging_df.alias(\"stage\").join(delta_df.alias(\"target\"), on=\"id\", how=\"inner\").where(updates_condition)\n",
    "updated_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(target.is_active = Y)'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_condition = col(\"target.is_active\") == \"Y\"\n",
    "# filter_condition\n",
    "\n",
    "# filtered_df = delta_df.join(staging_df, col(\"stage.id\")==col(\"target.id\"), how=\"leftsemi\").where(filter_condition)\n",
    "# filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = delta_df.alias(\"target\").join(staging_df.alias(\"stage\"), on=\"id\", how=\"leftsemi\").where(filter_condition)\n",
    "# filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_spec = Window.partitionBy(\"id\").orderBy(desc(\"extract_tmst\"), desc(monotonically_increasing_id()))\n",
    "# active_records = staging_df.withColumn(\"row_number\", row_number().over(window_spec))\n",
    "\n",
    "# active_records.show()\n",
    "\n",
    "# _active_records = active_records.filter(active_records[\"row_number\"] == 1).drop(\"row_number\")\n",
    "# _active_records.show()\n",
    "\n",
    "# _inactive_records = active_records.filter(active_records[\"row_number\"] != 1).drop(\"row_number\")\n",
    "# _inactive_records.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_surrogate_key = delta_df.selectExpr(\"max(surrogate_key)\").collect()[0][0]\n",
    "\n",
    "# if max_surrogate_key == None:\n",
    "#     max_surrogate_key = 0\n",
    "\n",
    "# _x = staging_df.withColumn(\"_x\", lit(max_surrogate_key +1))\n",
    "# _x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+----------+----------+-------------------+--------------------+--------------------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|first_name| last_name|       extract_tmst|              source|                hash|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+----------+----------+-------------------+--------------------+--------------------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|   Belinda|   Hendrix|2023-07-02 00:58:00|file:///Users/sai...|5620d42bea3b111f0...|\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|   Belinda|  Sullivan|2023-07-01 00:58:00|file:///Users/sai...|1863cefdfa2cde755...|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|   Sherlyn|Williamson|2023-07-01 00:58:00|file:///Users/sai...|bf96251ef7d0ab4d8...|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|      Lexi|     Walls|2023-07-01 00:58:00|file:///Users/sai...|83b9e894466f70135...|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+----------+----------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df = delta_df.alias(\"target\").join(staging_df.alias(\"stage\"), on=\"id\", how=\"inner\").where(filter_condition)\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+----------+----------+-------------------+--------------------+--------------------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|first_name| last_name|       extract_tmst|              source|                hash|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+----------+----------+-------------------+--------------------+--------------------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|   Belinda|   Hendrix|2023-07-02 00:58:00|file:///Users/sai...|5620d42bea3b111f0...|\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|   Belinda|  Sullivan|2023-07-01 00:58:00|file:///Users/sai...|1863cefdfa2cde755...|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|   Sherlyn|Williamson|2023-07-01 00:58:00|file:///Users/sai...|bf96251ef7d0ab4d8...|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|      Lexi|     Walls|2023-07-01 00:58:00|file:///Users/sai...|83b9e894466f70135...|\n",
      "|  6|   Shyanne|       Liu|file:///Users/sai...|547811bdef1d46e0a...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|      null|      null|               null|                null|                null|\n",
      "|  5|    Nathan|   Mcclain|file:///Users/sai...|e2cc62e08ad845909...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|      null|      null|               null|                null|                null|\n",
      "|  4|      Zoey|    Tucker|file:///Users/sai...|1818ea471269caa72...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|      null|      null|               null|                null|                null|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+----------+----------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df = delta_df.alias(\"target\").join(staging_df.alias(\"stage\"), on=\"id\", how=\"left\").where(filter_condition)\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name|last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  6|   Shyanne|      Liu|file:///Users/sai...|547811bdef1d46e0a...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  5|    Nathan|  Mcclain|file:///Users/sai...|e2cc62e08ad845909...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  4|      Zoey|   Tucker|file:///Users/sai...|1818ea471269caa72...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "+---+----------+---------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df = delta_df.alias(\"target\").join(staging_df.alias(\"stage\"), on=\"id\", how=\"leftanti\").where(filter_condition)\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/17 19:03:30 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "| id|first_name| last_name|              source|                hash|is_active|         start_tmst|           end_tmst|        create_tmst|        update_tmst|created_by_exec_id|updated_by_exec_id|year|month|day|hour|minute|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "|  1|   Belinda|  Sullivan|file:///Users/sai...|1863cefdfa2cde755...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  3|   Sherlyn|Williamson|file:///Users/sai...|bf96251ef7d0ab4d8...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  2|      Lexi|     Walls|file:///Users/sai...|83b9e894466f70135...|        Y|2023-07-01 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  6|   Shyanne|       Liu|file:///Users/sai...|547811bdef1d46e0a...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  5|    Nathan|   Mcclain|file:///Users/sai...|e2cc62e08ad845909...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "|  4|      Zoey|    Tucker|file:///Users/sai...|1818ea471269caa72...|        Y|2023-07-02 00:58:00|2999-12-31 23:59:59|2023-07-17 19:02:44|2023-07-17 19:02:44|                 1|                 1|2023|   07| 17|  19|    02|\n",
      "+---+----------+----------+--------------------+--------------------+---------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+----+-----+---+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_path = f\"{os.getcwd()}/delta\"\n",
    "\n",
    "delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "\n",
    "delta_table.alias(\"target\").merge(\n",
    "        new_records.alias(\"updates\"),\n",
    "        \"target.id==updates.id\"\n",
    "    ).whenMatchedUpdateAll(\n",
    "    ).whenNotMatchedInsertAll(\n",
    "    ).execute()\n",
    "\n",
    "delta_table_df = delta_table.toDF()\n",
    "delta_table_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_scd2(updates_df, condition):\n",
    "    delta_schema_str = (\n",
    "        \"id int,first_name string,last_name string, source string, hash string, start_tmst timestamp, end_tmst timestamp, \"\n",
    "        \"create_tmst timestamp, update_tmst timestamp, created_by_exec_id int, updated_by_exec_id int, \"\n",
    "        \"year string, month string, day string, hour string, minute string\"\n",
    "    )\n",
    "\n",
    "    delta_schema = _parse_datatype_string(delta_schema_str)\n",
    "    delta_path = f\"{os.getcwd()}/delta\"\n",
    "\n",
    "    partition_columns = [\"year\", \"month\", \"day\", \"hour\", \"minute\"]\n",
    "\n",
    "    if not DeltaTable.isDeltaTable(spark, delta_path):\n",
    "        print(\"Not a delta table. Creating delta table...\")\n",
    "        empty_df = spark.createDataFrame([], delta_schema)\n",
    "\n",
    "        empty_df.write.format(\"delta\") \\\n",
    "                    .mode(\"append\") \\\n",
    "                    .partitionBy(*partition_columns) \\\n",
    "                    .save(delta_path)\n",
    "\n",
    "    delta_table = DeltaTable.forPath(spark, delta_path)\n",
    "\n",
    "    delta_table.alias(\"target\").merge(\n",
    "            updates_df.alias(\"updates\"),\n",
    "            condition\n",
    "        ).whenMatchedUpdateAll(\n",
    "        ).whenNotMatchedInsertAll(\n",
    "        ).execute()\n",
    "\n",
    "    delta_table_df = delta_table.toDF()\n",
    "    delta_table_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve hash in UPDATE clause given columns updates.id, updates.first_name, updates.last_name, updates.extract_date, updates.source",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m delta_scd2(staging_df, \u001b[39m\"\u001b[39;49m\u001b[39mtarget.id==updates.id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[58], line 24\u001b[0m, in \u001b[0;36mdelta_scd2\u001b[0;34m(updates_df, condition)\u001b[0m\n\u001b[1;32m     17\u001b[0m     empty_df\u001b[39m.\u001b[39mwrite\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39mdelta\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[1;32m     18\u001b[0m                 \u001b[39m.\u001b[39mmode(\u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m) \\\n\u001b[1;32m     19\u001b[0m                 \u001b[39m.\u001b[39mpartitionBy(\u001b[39m*\u001b[39mpartition_columns) \\\n\u001b[1;32m     20\u001b[0m                 \u001b[39m.\u001b[39msave(delta_path)\n\u001b[1;32m     22\u001b[0m delta_table \u001b[39m=\u001b[39m DeltaTable\u001b[39m.\u001b[39mforPath(spark, delta_path)\n\u001b[0;32m---> 24\u001b[0m delta_table\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mmerge(\n\u001b[1;32m     25\u001b[0m         updates_df\u001b[39m.\u001b[39;49malias(\u001b[39m\"\u001b[39;49m\u001b[39mupdates\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m     26\u001b[0m         condition\n\u001b[1;32m     27\u001b[0m     )\u001b[39m.\u001b[39;49mwhenMatchedUpdateAll(\n\u001b[1;32m     28\u001b[0m     )\u001b[39m.\u001b[39;49mwhenNotMatchedInsertAll(\n\u001b[1;32m     29\u001b[0m     )\u001b[39m.\u001b[39;49mexecute()\n\u001b[1;32m     31\u001b[0m delta_table_df \u001b[39m=\u001b[39m delta_table\u001b[39m.\u001b[39mtoDF()\n\u001b[1;32m     32\u001b[0m delta_table_df\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aws/lib/python3.9/site-packages/delta/tables.py:924\u001b[0m, in \u001b[0;36mDeltaMergeBuilder.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39m@since\u001b[39m(\u001b[39m0.4\u001b[39m)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[39m    Execute the merge operation based on the built matched and not matched actions.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m \n\u001b[1;32m    922\u001b[0m \u001b[39m    See :py:class:`~delta.tables.DeltaMergeBuilder` for complete usage details.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jbuilder\u001b[39m.\u001b[39;49mexecute()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aws/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aws/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve hash in UPDATE clause given columns updates.id, updates.first_name, updates.last_name, updates.extract_date, updates.source"
     ]
    }
   ],
   "source": [
    "delta_scd2(staging_df, \"target.id==updates.id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
